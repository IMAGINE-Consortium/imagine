{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Including new observational data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will see how to load observational data onto IMAGINE. \n",
    "\n",
    "Both observational and simulated data are manipulated within IMAGINE through *observable dictionaries*. There are three types of these: `Measurements`, `Simulations` and `Covariances`, which can store multiple entries of observational, simulated and covariance (either real or mock) data, respectively. Appending data to an `ObservableDict` requires following some requirements regarding the data format, therefore we recomend the use of one of the `Dataset` classes.\n",
    "\n",
    "\n",
    "## HEALPix Datasets \n",
    "\n",
    "Let us illustrate how to prepare an IMAGINE dataset with the Faraday depth map obtained by Oppermann et al. 2012 ([arXiv:1111.6186](https://arxiv.org/abs/1111.6186)). \n",
    "\n",
    "The following snippet will download the [data](https://wwwmpa.mpa-garching.mpg.de/ift/faraday/2012/index.html) (a ~4MB FITS file) to RAM and open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: <class '_io.BytesIO'>\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       7   ()      \n",
      "  1  TEMPERATURE    1 BinTableHDU     17   196608R x 1C   [E]   \n",
      "  2  signal uncertainty    1 BinTableHDU     17   196608R x 1C   [E]   \n",
      "  3  Faraday depth    1 BinTableHDU     17   196608R x 1C   [E]   \n",
      "  4  Faraday uncertainty    1 BinTableHDU     17   196608R x 1C   [E]   \n",
      "  5  galactic profile    1 BinTableHDU     17   196608R x 1C   [E]   \n",
      "  6  angular power spectrum of signal    1 BinTableHDU     12   384R x 1C   [E]   \n"
     ]
    }
   ],
   "source": [
    "import requests, io\n",
    "from astropy.io import fits\n",
    "\n",
    "download = requests.get('https://wwwmpa.mpa-garching.mpg.de/ift/faraday/2012/faraday.fits')\n",
    "raw_dataset = fits.open(io.BytesIO(download.content))\n",
    "raw_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will feed this to an IMAGINE `Dataset`. It requires \n",
    "converting the data into a proper numpy array of floats. \n",
    "To allow this notebook running on a small memory laptop, we\n",
    "will also reduce the size of the arrays (only taking 1 value every 256)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.observables import FaradayDepthHEALPixDataset\n",
    "import numpy as np\n",
    "from astropy import units as u\n",
    "import healpy as hp\n",
    "\n",
    "# Adjusts the data to the right format\n",
    "fd_raw = raw_dataset[3].data.astype(np.float)\n",
    "sigma_fd_raw = raw_dataset[4].data.astype(np.float)\n",
    "# Makes it smaller, to save memory\n",
    "fd_raw = hp.pixelfunc.ud_grade(fd_raw, 64)\n",
    "sigma_fd_raw = hp.pixelfunc.ud_grade(sigma_fd_raw, 64)\n",
    "# We need to include units the data\n",
    "# (this avoids later errors and inconsistencies)\n",
    "fd_raw *= u.rad/u.m/u.m\n",
    "sigma_fd_raw *= u.rad/u.m/u.m\n",
    "# Loads into a Dataset\n",
    "dset = FaradayDepthHEALPixDataset(data=fd_raw, error=sigma_fd_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important assumption in the previous code-block is that the covariance matrix is diagonal, i.e. that the errors in FD are *uncorrelated*. \n",
    "If this is not\n",
    "the case, instead of initializing the `FaradayDepthHEALPixDataset` with `data` and `error`, one should initialize it with `data` and `cov`, where the latter\n",
    "is the correct covariance matrix.\n",
    "\n",
    "To keep things organised and useful, we *strongly recommend* to create a \n",
    "personalised `dataset` class and make it available to the rest of the\n",
    "consortium in the [imagine-datasets](https://github.com/IMAGINE-Consortium/imagine-datasets) GitHub repository. \n",
    "An example of such a class is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.observables import FaradayDepthHEALPixDataset\n",
    "\n",
    "class FaradayDepthOppermann2012(FaradayDepthHEALPixDataset):\n",
    "    def __init__(self, Nside=None):\n",
    "        # Fetches and reads the \n",
    "        download = requests.get('https://wwwmpa.mpa-garching.mpg.de/ift/faraday/2012/faraday.fits')\n",
    "        raw_dataset = fits.open(io.BytesIO(download.content))\n",
    "        # Adjusts the data to the right format\n",
    "        fd_raw = raw_dataset[3].data.astype(np.float)\n",
    "        sigma_fd_raw = raw_dataset[4].data.astype(np.float)\n",
    "        # Reduces the resolution\n",
    "        if Nside is not None:\n",
    "            fd_raw = hp.pixelfunc.ud_grade(fd_raw, Nside)\n",
    "            sigma_fd_raw = hp.pixelfunc.ud_grade(sigma_fd_raw, Nside)\n",
    "        # Includes units in the data\n",
    "        fd_raw *= u.rad/u.m/u.m\n",
    "        sigma_fd_raw *= u.rad/u.m/u.m\n",
    "        # Loads into the Dataset\n",
    "        super().__init__(data=fd_raw, error=sigma_fd_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this pre-programmed, anyone will be able to load this into the pipeline by simply doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = FaradayDepthOppermann2012(Nside=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a dataset, we can load this into a Measurements and Covariances objects (which will be discussed a further down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.observables import Measurements, Covariances\n",
    "\n",
    "# Creates the instances\n",
    "mea = Measurements()\n",
    "cov = Covariances()\n",
    "\n",
    "# Appends the data\n",
    "mea.append(dataset=dset)\n",
    "cov.append(dataset=dset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Datasets \n",
    "\n",
    "So far, we looked into datasets comprising [HEALPix](https://healpix.sourceforge.io/) maps. One may also want to\n",
    "work with *tabular* datasets.  We exemplify this fetching and preparing a RM\n",
    "catalogue of Mao et al 2010 ([arXiv:1003.4519](https://arxiv.org/abs/1003.4519)). \n",
    "In the case of this particular dataset, we can import the data from VizieR using the `astroquery` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=3</i>\n",
       "<table id=\"table140276050629840\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>RAJ2000</th><th>DEJ2000</th><th>GLON</th><th>GLAT</th><th>RM</th><th>e_RM</th><th>PI</th><th>I</th><th>S5.2</th><th>f_S5.2</th><th>NVSS</th></tr></thead>\n",
       "<thead><tr><th>&quot;h:m:s&quot;</th><th>&quot;d:m:s&quot;</th><th>deg</th><th>deg</th><th>rad / m2</th><th>rad / m2</th><th>mJy</th><th>mJy</th><th></th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>bytes11</th><th>bytes11</th><th>float32</th><th>float32</th><th>int16</th><th>int16</th><th>float32</th><th>float64</th><th>bytes3</th><th>bytes1</th><th>bytes4</th></tr></thead>\n",
       "<tr><td>13 07 08.33</td><td>+24 47 00.7</td><td>0.21</td><td>85.76</td><td>-3</td><td>4</td><td>7.77</td><td>131.49</td><td>Yes</td><td></td><td>NVSS</td></tr>\n",
       "<tr><td>13 35 48.14</td><td>+20 10 16.0</td><td>0.86</td><td>77.70</td><td>3</td><td>5</td><td>8.72</td><td>71.47</td><td>No</td><td>b</td><td>NVSS</td></tr>\n",
       "<tr><td>13 24 14.48</td><td>+22 13 13.1</td><td>1.33</td><td>81.08</td><td>-6</td><td>6</td><td>7.62</td><td>148.72</td><td>Yes</td><td></td><td>NVSS</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=3>\n",
       "  RAJ2000     DEJ2000     GLON    GLAT  ...    I      S5.2  f_S5.2  NVSS \n",
       "  \"h:m:s\"     \"d:m:s\"     deg     deg   ...   mJy                        \n",
       "  bytes11     bytes11   float32 float32 ... float64  bytes3 bytes1 bytes4\n",
       "----------- ----------- ------- ------- ... -------- ------ ------ ------\n",
       "13 07 08.33 +24 47 00.7    0.21   85.76 ...   131.49    Yes          NVSS\n",
       "13 35 48.14 +20 10 16.0    0.86   77.70 ...    71.47     No      b   NVSS\n",
       "13 24 14.48 +22 13 13.1    1.33   81.08 ...   148.72    Yes          NVSS"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import astroquery\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "# Fetches the relevant catalogue from Vizier\n",
    "# (see https://astroquery.readthedocs.io/en/latest/vizier/vizier.html for details)\n",
    "catalog = Vizier.get_catalogs('J/ApJ/714/1170')[0]\n",
    "catalog[:3] # Shows only first rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure for converting this to an IMAGINE data set is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.observables import TabularDataset\n",
    "dset_tab = TabularDataset(catalog, name='fd', tag=None,\n",
    "                          units= u.rad/u.m/u.m,\n",
    "                          data_col='RM', err_col='e_RM', \n",
    "                          lat_col='GLAT', lon_col='GLON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`catalog` must be a dictionary-like object (e.g. `dict`, `astropy.Tables`, `pandas.DataFrame`) and data(/error/lat/lon)\\_column specify the key/column-name used to retrieve the relevant data from `catalog`.  The `name` argument specifies the type of measurement that is being stored. This has to agree with the requirements of the Simulator you will use. Some standard available observable names are:\n",
    "\n",
    "* 'fd' - Faraday depth\n",
    "* 'sync' - Synchrotron emission, needs the `tag` to be interpreted\n",
    "    * tag = 'I' - Total intensity\n",
    "    * tag = 'Q' - Stokes Q\n",
    "    * tag = 'U' - Stokes U\n",
    "    * tag = 'PI' - polarisation intensity \n",
    "    * tag = 'PA' - polarisation angle\n",
    "* 'dm' - Dispersion measure\n",
    "\n",
    "The units are provided as an `astropy.units.Unit` object and are converted internally to the requirements of the specific Simulator being used.\n",
    "\n",
    "Again, the procedure can be packed and distributed to the community in a (very short!) personalised class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.vizier import Vizier\n",
    "from imagine.observables import TabularDataset\n",
    "\n",
    "class FaradayRotationMao2010(TabularDataset):\n",
    "    def __init__(self):\n",
    "        # Fetches the catalogue\n",
    "        catalog = Vizier.get_catalogs('J/ApJ/714/1170')[0]\n",
    "        # Reads it to the TabularDataset (the catalogue obj actually contains units)\n",
    "        super().__init__(catalog, name='fd', units=catalog['RM'].unit,\n",
    "                         data_col='RM', err_col='e_RM', \n",
    "                         lat_col='GLAT', lon_col='GLON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_tab = FaradayRotationMao2010() # ta-da!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements and Covariances\n",
    "\n",
    "Again, we can include these observables in our `Measurements` and `Covariances` objects. These are dictionary-like object, i.e. given a key, one can access a \n",
    "given item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement keys:\n",
      "\t ('fd', None, 64, None)\n",
      "\t ('fd', None, 'tab', None)\n",
      "\n",
      "Covariance keys:\n",
      "\t ('fd', None, 64, None)\n",
      "\t ('fd', None, 'tab', None)\n"
     ]
    }
   ],
   "source": [
    "mea.append(dataset=dset_tab)\n",
    "cov.append(dataset=dset_tab)\n",
    "\n",
    "print('Measurement keys:')\n",
    "for k in mea.keys():\n",
    "    print('\\t',k)\n",
    "print('\\nCovariance keys:')\n",
    "for k in cov.keys():\n",
    "    print('\\t',k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys follow a strict convention:\n",
    "``(data-name,data-freq,Nside/'tab',ext)``\n",
    "\n",
    "* If data is independent from frequency, data-freq is set `None`, otherwise it is the frequency in GHz.\n",
    "* The third value in the key-tuple is the HEALPix Nside (for maps) or the string 'tab' for tabular data. \n",
    "* Finally, the last value, `ext` can be 'I','Q','U','PI','PA', None or other customized tags depending on the nature of the observable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually including data\n",
    "\n",
    "An alternative way to include data into an Observables dictionary is explicitly choosing the key and adjusting the data shape. One can see how this is handled by the Dataset object in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key used in the \"name\" arg was: ('fd', None, 64, None)\n",
      "The shape of data used in the \"new\" arg was: (1, 49152)\n"
     ]
    }
   ],
   "source": [
    "# This is how HEALPix data can be included without the mediation of Datasets:\n",
    "mea.append(name=dset.key, data=dset.data)\n",
    "# The units of covariance matrices have to be provided separately\n",
    "# (as sparse matrices to not support them)\n",
    "cov.append(name=dset.key, data=dset.cov, unit=dset.cov_unit)\n",
    "# This is what Dataset is doing:\n",
    "print('The key used in the \"name\" arg was:', dset.key)\n",
    "print('The shape of data used in the \"new\" arg was:', dset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what exactly is stored in `mea` and `cov`?  This is handled by an `Observable` object.\n",
    "Here we illustrate with the tabular dataset previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'imagine.observables.observable.Observable'>\n",
      "mea.data: array([[ -3.,   3.,  -6.,   0.,   4.,  -6.,   5.,  -1.,  -6.,   1., -14.,\n",
      "         14.,   3.,  10.,  12.,  16.,  -3.,   5.,  12.,   6.,  -1.,   5.,\n",
      "          5.,  -4.,  -1.,   9.,  -1., -13.,   4.,   5.,  -5.,  17., -10.,\n",
      "          8.,   0.,   1.,   5.,   9.,   5., -12., -17.,   4.,   2.,  -1.,\n",
      "         -3.,   3.,  16.,  -1.,  -1.,   3.]])\n",
      "mea.data.shape: (1, 50)\n",
      "mea.unit Unit(\"rad / m2\")\n",
      "mea.coords (coordinates dict -- for tabular datasets only):\n",
      " {'type': 'galactic', 'lon': <Quantity [ 0.21,  0.86,  1.33,  1.47,  2.1 ,  2.49,  3.11,  3.93,  4.17,\n",
      "            5.09,  5.09,  5.25,  5.42,  6.36, 12.09, 12.14, 13.76, 13.79,\n",
      "           14.26, 14.9 , 17.1 , 20.04, 20.56, 20.67, 20.73, 20.85, 21.83,\n",
      "           22.  , 22.13, 22.24, 22.8 , 23.03, 24.17, 24.21, 24.28, 25.78,\n",
      "           25.87, 28.84, 28.9 , 30.02, 30.14, 30.9 , 31.85, 34.05, 34.37,\n",
      "           34.54, 35.99, 37.12, 37.13, 37.2 ] deg>, 'lat': <Quantity [85.76, 77.7 , 81.08, 81.07, 83.43, 82.16, 84.8 , 78.53, 85.81,\n",
      "           79.09, 81.5 , 79.69, 80.61, 80.85, 79.87, 81.64, 77.15, 77.12,\n",
      "           82.52, 84.01, 80.26, 85.66, 82.42, 77.73, 78.94, 80.75, 80.77,\n",
      "           80.77, 82.72, 80.24, 77.17, 82.19, 82.62, 81.42, 79.25, 85.63,\n",
      "           81.66, 78.74, 78.72, 79.92, 89.52, 77.32, 87.09, 86.11, 85.04,\n",
      "           85.05, 78.73, 79.1 , 80.74, 84.35] deg>}\n",
      "mea.dtype: measured\n",
      "\n",
      "\n",
      "cov type <class 'imagine.observables.observable.Observable'>\n",
      "cov.data type: <class 'numpy.ndarray'>\n",
      "cov.data.shape: (50, 50)\n",
      "cov.dtype: covariance\n"
     ]
    }
   ],
   "source": [
    "print(type(mea[dset_tab.key]))\n",
    "print('mea.data:', repr(mea[dset_tab.key].data))\n",
    "print('mea.data.shape:', mea[dset_tab.key].data.shape)\n",
    "print('mea.unit', repr(mea[dset_tab.key].unit))\n",
    "print('mea.coords (coordinates dict -- for tabular datasets only):\\n', \n",
    "      mea[dset_tab.key].coords)\n",
    "print('mea.dtype:', mea[dset_tab.key].dtype)\n",
    "print('\\n\\ncov type',type(cov[dset_tab.key]))\n",
    "print('cov.data type:', type(cov[dset_tab.key].data))\n",
    "print('cov.data.shape:', cov[dset_tab.key].data.shape)\n",
    "print('cov.dtype:', cov[dset_tab.key].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataset` object may also automatically distribute the data across different nodes if one is running the code using MPI parallelisation \n",
    "-- a strong reason for sticking to using `Datasets` instead of appending directly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (imagine)",
   "language": "python",
   "name": "imagine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
