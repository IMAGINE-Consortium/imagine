{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGINE tutorial 2\n",
    "\n",
    "## Another pipeline example and parallel computing features\n",
    "\n",
    "Tutorial 1 briefly went through some of the basic features of IMAGINE. \n",
    "We will now perform same analysis on a different field model, this is will \n",
    "give an idea of how some fields are easier to determine than others using \n",
    "these methods.\n",
    "\n",
    "#### ...imagine running all this in parallel...\n",
    "\n",
    "The present tutorial also ilustrates the IMAGINE's MPI support. To be able\n",
    "to do this within a Jupyter notebook, we wiil use the \n",
    "[ipyparallel](https://ipyparallel.readthedocs.io/en/latest/mpi.html) package. \n",
    "Thus, before running this notebook, you will need to start *ipython cluster* \n",
    "executing the following command on the same machine:\n",
    "```\n",
    "$ ipcluster start -n 4 --engines=MPIEngineSetLauncher\n",
    "```\n",
    "\n",
    "where the number of cores, set using the argumen `-n` can be changed to something \n",
    "else if needed.\n",
    "\n",
    "#### ...imagine a different emission...\n",
    "\n",
    "The field in this tutorial is designed to mimick emission intensities which is roughly proportional to (Galactic) magnetic field energy density, e.g. field  strength squared.\n",
    "\n",
    "$ signal(x) = [\\sin(x) \\times \\mathcal{G}(\\mu=a_0,\\sigma=b_0;seed=s)]^2 \\,, \\; x \\in (0,2\\pi)$\n",
    "\n",
    "You will see that the influence of having variance-like fluctuations in the observable differs _dramatically_ from what we have seen in tutorial 1.\n",
    "\n",
    "This tutorial has a threshold in data size, i.e. taking $ size<5 $ in this tutorial will fail.\n",
    "\n",
    "<span style=\"color:red\">**NB the following Bayesian sampling processes can be quite expensive**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up parallel environment\n",
    "\n",
    "To allow [ipyparallel](https://ipyparallel.readthedocs.io/en/latest/mpi.html)  to work,\n",
    "one must first connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-20e90a52be44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mipyparallel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mipp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mipp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/site-packages/ipyparallel/client/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url_file, profile, profile_dir, ipython_dir, context, debug, sshserver, sshkey, password, paramiko, timeout, cluster_id, **extra_args)\u001b[0m\n\u001b[1;32m    406\u001b[0m                     \u001b[0mwaiting_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0mwaiting_time\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwaiting_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                         \u001b[0mwaiting_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "cluster = ipp.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the notebook is connected to the different ipyparellel processes running. \n",
    "The relevant packages need to be imported by all processes, this can be done \n",
    "through the *notebook magic* `%%px`, which instructs that the cell should be \n",
    "run by the ipcluster processes instead of the notebook's main kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "import logging as log\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imagine.observables.observable_dict as observable_dict\n",
    "from imagine.likelihoods.ensemble_likelihood import EnsembleLikelihood\n",
    "from imagine.fields.test_field.test_field_factory import TestFieldFactory\n",
    "from imagine.priors.flat_prior import FlatPrior\n",
    "from imagine.simulators.test.bi_simulator import BiSimulator\n",
    "from imagine.tools.covariance_estimator import oas_cov\n",
    "\n",
    "import corner, matplotlib\n",
    "from imagine.tools.carrier_mapper import unity_mapper\n",
    "from imagine.tools.mpi_helper import mpi_eye\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# Sets up parallel features\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "mpirank = comm.Get_rank()\n",
    "mpisize = comm.Get_size()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Preparation of mock data\n",
    "\n",
    "As in tutorial 1 (we refer the reader there for details) we first \n",
    "construct our mock data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "\n",
    "a0 = 3. # true value of a\n",
    "b0 = 6. # true value of b\n",
    "e = 0.1 # std of gaussian measurement error\n",
    "s = 233 # seed fixed for signal field\n",
    "\n",
    "size = 20\n",
    "x = np.linspace(0,2.*np.pi,size)\n",
    "\n",
    "np.random.seed(s)\n",
    "\n",
    "# Constructs the signal array\n",
    "signal = np.square (np.sin(x) * np.random.normal(loc=a0, scale=b0, size=size))\n",
    "# The data will include random noise\n",
    "data = np.vstack([signal + np.random.normal(loc=0., scale=e, size=size)])\n",
    "# We assume a diagonal covariance matrix\n",
    "cov = (e**2) * mpi_eye(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that [mpi_eye](https://imagine-code.readthedocs.io/en/mpi-tutorial/imagine.tools.html#imagine.tools.mpi_helper.mpi_eye) is used instead of `numpy.eye`. This produces \n",
    "the two-dimensional identity matrix which is already distributed\n",
    "among different processes. This is shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "print(cov.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed data can then be loaded into [observable_dict](https://imagine-code.readthedocs.io/en/mpi-tutorial/imagine.observables.html#module-imagine.observables.observable_dict) objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "# We can add the mock data to an IMAGINE Measurements object\n",
    "mock_data = observable_dict.Measurements()\n",
    "mock_data.append(('test', 'nan', str(size), 'nan'), data, True)\n",
    "# Likewise, can can create a IMAGINE Covariances object\n",
    "mock_cov = observable_dict.Covariances() \n",
    "mock_cov.append(('test', 'nan', str(size), 'nan'), cov, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The property [global_data](https://imagine-code.readthedocs.io/en/mpi-tutorial/imagine.observables.html#imagine.observables.observable.Observable.global_data) gathers the distributed measurement or covariance data from all\n",
    "processes and returns an array at the root process. Other processes get `None`.\n",
    "The attribute [data](https://imagine-code.readthedocs.io/en/mpi-tutorial/imagine.observables.html#imagine.observables.observable.Observable) contains the *local* measurement or covariance data.\n",
    "\n",
    "Below, we exemplify the use of these for plotting. (Note that the error bars are too small\n",
    "to be visible.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "full_mock_data = mock_data[('test', 'nan', str(size), 'nan')].global_data\n",
    "full_mock_cov = mock_cov[('test', 'nan', str(size), 'nan')].global_data\n",
    "\n",
    "if full_mock_data is not None:\n",
    "    error = np.sqrt(full_mock_cov.diagonal()) # The variance is in the diagonal \n",
    "    plt.errorbar(x, full_mock_data[0], error, linestyle='',\n",
    "                 marker='.', label='measurement')\n",
    "    plt.plot(x,(np.sin(x)*a0)**2,'r--', label='$\\sin(x)$')\n",
    "    plt.xlabel('x'); plt.ylabel('mock data'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Preparation of pipeline\n",
    "\n",
    "As in tutorial one, we need to set up a [field factory](https://imagine-code.readthedocs.io/en/mpi-tutorial/imagine.fields.test_field.html#imagine.fields.test_field.test_field_factory.TestFieldFactory), which again \n",
    "produces scalar fields of the form $f(x) = a x + \\mathcal{G}(b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "factory = TestFieldFactory(active_parameters=('a','b'))\n",
    "# adjust parameter range for Bayesian analysis\n",
    "factory.parameter_ranges = {'a':(0,10),'b':(0,10)}\n",
    "factory_list = [factory]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulator used for this example is the [BiSimulator](https://imagine-code.readthedocs.io/en/mpi-tutorial/imagine.simulators.test.html#imagine.simulators.test.bi_simulator.BiSimulator), \n",
    "consisting of the emissivity function shown in the beginning of this notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "simer = BiSimulator(mock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final ingredients for assembling the pipeline are a prior (flat) and setting up the\n",
    "object that computes the ensemble likelyhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "prior = FlatPrior()\n",
    "likelihood = EnsembleLikelihood(mock_data, mock_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) Rolling out with MultiNest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can assemble and run our pipline. \n",
    "Note parameters that control the sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px \n",
    "from imagine.pipelines.multinest_pipeline import MultinestPipeline\n",
    "# Assembly\n",
    "ensemble_size = 100\n",
    "pipeline_multinest = MultinestPipeline(simer, factory_list, likelihood, prior, ensemble_size)\n",
    "# Configuration\n",
    "pipeline_multinest.random_type = 'controllable'\n",
    "pipeline_multinest.seed_tracer = 23\n",
    "pipeline_multinest.sampling_controllers = {'n_iter_before_update': 10,\n",
    "                                           'n_live_points': 400,\n",
    "                                           'verbose': True,\n",
    "                                           'resume': False}\n",
    "# Run\n",
    "results_multinest = pipeline_multinest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, after all this waiting, we can visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "if mpirank == 0:\n",
    "    samples = results_multinest['samples']\n",
    "    # convert variables into parameters\n",
    "    params = pipeline_multinest.active_parameters\n",
    "    for i, param in enumerate(params): \n",
    "        low, high = pipeline_multinest.active_ranges[param]\n",
    "        for j, sample in enumerate(samples[:,i]):\n",
    "            samples[j, i] = unity_mapper(samples[j, i], low, high)\n",
    "    \n",
    "    # corner plot\n",
    "    corner.corner(samples[:, :len(params)],\n",
    "                          range=[0.99]*len(params),\n",
    "                          quantiles=[0.02, 0.5, 0.98],\n",
    "                          labels=params,\n",
    "                          show_titles=True,\n",
    "                          title_kwargs={\"fontsize\": 20},\n",
    "                          color='steelblue',\n",
    "                          truths=[a0,b0],\n",
    "                          truth_color='firebrick',\n",
    "                          plot_contours=True,\n",
    "                          hist_kwargs={'linewidth': 2},\n",
    "                          label_kwargs={'fontsize': 20})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Rolling out with Dynesty\n",
    "\n",
    "_Current, parallel execution using Dynesty is **not** supported. The following two cells are a placeholder for the near future._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "from imagine.pipelines.dynesty_pipeline import DynestyPipeline\n",
    "# Assembly\n",
    "simulation_size = 100\n",
    "pipe_dynesty = DynestyPipeline(simer, factory_list, likelihood,\n",
    "                               prior, simulation_size)\n",
    "# Configuration\n",
    "pipe_dynesty.random_type = 'controllable'\n",
    "pipe_dynesty.seed_tracer = int(23)\n",
    "pipe_dynesty.sampling_controllers = {'nlive': 10}\n",
    "# Run\n",
    "results_dynesty = pipe_dynesty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "if mpirank == 0:\n",
    "    samples = results_dynesty['samples']\n",
    "    # convert variables into parameters\n",
    "    params = pipeline_dynesty.active_parameters\n",
    "    for i, param in enumerate(params): \n",
    "        low, high = pipeline_dynesty.active_ranges[param]\n",
    "        for j, sample in enumerate(samples[:,i]):\n",
    "            samples[j, i] = unity_mapper(samples[j, i], low, high)\n",
    "    \n",
    "    # corner plot\n",
    "    corner.corner(samples[:, :len(params)],\n",
    "                          range=[0.99]*len(params),\n",
    "                          quantiles=[0.02, 0.5, 0.98],\n",
    "                          labels=params,\n",
    "                          show_titles=True,\n",
    "                          title_kwargs={\"fontsize\": 20},\n",
    "                          color='steelblue',\n",
    "                          truths=[a0,b0],\n",
    "                          truth_color='firebrick',\n",
    "                          plot_contours=True,\n",
    "                          hist_kwargs={'linewidth': 2},\n",
    "                          label_kwargs={'fontsize': 20})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convergence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "from scipy.stats import norm\n",
    "repeat = 4\n",
    "for i in range(repeat):\n",
    "    tmp = pipeline_multinest()\n",
    "    asamp = tmp['samples'][:,0]\n",
    "    bsamp = tmp['samples'][:,1]\n",
    "    matplotlib.pyplot.hist(asamp,30,histtype='step',stacked=True,fill=True,color='firebrick',alpha=0.1)\n",
    "    matplotlib.pyplot.hist(bsamp,30,histtype='step',stacked=True,fill=True,label='b',color='steelblue',alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This ends tutorial 2 \n",
    "\n",
    "The python script for tutorial 2 can be found in [bisimulator_multinest](https://github.com/IMAGINE-Consortium/imagine/blob/mpi/examples/test_examples/bisimulator_multinest.py) and [bisimulator_dynesty](https://github.com/IMAGINE-Consortium/imagine/blob/mpi/examples/test_examples/bisimulator_dynesty.py)\n",
    "\n",
    "Or see more examples in the *imagine/examples* directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
